\section{BACKGROUND AND LITERATURE REVIEW}

\subsection{Introductory Statement}

% context - provide some context to orient those readers who are less familiar with your topic and to establish the importance of your work.

% concepts - core concepts/notions that are required for the reader to know in order to understand your work

% need/motivation - state the need for your work, as an opposition between what the scientific community currently has and what it wants.

% position - positioning the research to carry out

% your contributions

%%%%%%%%%%%%%%%%%%% From reading Kenny's stage 2 %%%%%%%%%%%%%%%%%%%
% 3.1 Introductory Statement

% ?: more studies about the Automated chest radiograph interpretation.
% * A lot of information about datasets in \citet{SeyyedKalantari2020CheXclusion}

%  

%%%%%% Labeler %%%%%%
% Compared to other dataset, the CXR often come with the report from radiologists
% rather than a clear label. In favor of training machine learning algorithm, we
% need a labeler to extract class labels from report text.

%%%%%% Datasets %%%%%%
% 1. MIMIC CHR, 371,920 chest x-rays associated with 227,943 imaging studies
% sourced from the Beth Israel Deaconess Medical Center between 2011 - 2016.
% 2. PadChest
% 3. Open-I
% 4. CheXpert (224,316 chest radiographs of 65,240 patients) from Stanford
% Hospital, erformed between October 2002 and July 2017 in both inpatient and
% outpatient centers, along with their associated radiology reports.

%%%%%% Additional dataset %%%%%%
% REFLACX
% EyeGaze



% p.1 General talk about AI.
% ! Need to put some reference here.
With the outstanding performance of deep learning model, Artificial intelligent (AI) system have began to be adopted and impact various industries, including transportation, manufacturing, advertising, financial and medical industries. Using deep learning not only provides a high performance outcome, it also frees people from monotonous and complicated feature engineering works. The non-necessity of feature engineering makes it a perfect choice on handling unstructured data, such as image and text, which has been proven with astonishing results. \\


% p.2 Why the medical AI is needed.
One practical field adopting AI approaches is chest X-ray (CXR) interpretation. When patients is asked to take a X-ray, a still chest X-ray image will be developed for the radiologists to identify the diseases and injuries. Reading the CXR-image can be time-consuming and painstaking. Even the expert radiologists can have diagnosis error caused by fatigue or extrinsic distractions \citep{Waite2017RadiologistError}. Moreover, in many areas over the world, the shortage of radiologists occurs even in developed countries \citep{Sunshine2004RadiologyShortageUS} \citep{Rimmer2017RadiologistShortageUk}. A serious shortage of radiologists can increase the already heavy burden of workload for radiologists, which exacerbates the concern of fatigue mentioned above. An interactive AI-system can assist the radiologists to conduct more efficient interpretation by providing the professional radiologist with pre-identified suspicious areas and lesions. After the abnormalities have been located, radiologists can take less effort to only work on confirming the predictions and finalising the report. \\

% p.3 current implementation of deep learning on medical.
Since the deep learning is well known for processing image data. Enormous amount of studies have been explored for automated diagnosis conducted by AI-based predictive systems. \citet{Rajpurkar2017CheXNet} proposed CheXNet, which consists of 121-layer of Convolution Neural Network (CNN) to detect pneumonia by Chest X-ray images. CheXNet achieved 0.425 on F1 score, which outperforms practicing radiologist average of 0.387. Furthermore, a report text can also generated by only providing CXR image. \citet{Liu2019ReportGeneration} cooperate the CNN encoder, RNN decoder and reinforcement learning to generate the clinical report with human-level quality. With the works mentioned, the deep learning approach has been proven to generate valuable results. Those results can then be helpful for radiologists when they're interpreting Chest X-ray images. \\

% p.4 The need of XAI.
The deep neural network hold the nature of non-linearity and large amount of parameters, which allows it to fit complex functions. However, since the non-linearity in its activation functions, current neural networks can't provide its own insight of decision making process to human leading to the concern of reliability. In some cases, a wrong decision can be extremely expensive. For example, an incorrect decision on buy/sell stocks can cause the company to loss million dollars on the market. And, when a medical AI system provide a faulty prescription, it may result in an irreversible damage on patients. \\

As we known the serious impact on inaccurate prediction of model, governments and organisations have announced policies to manage and regulate the use of AI system. These policies protect the right of data subject who can be affected significantly by a the prediction of AI models. A well known example is the article 22 in General Data Protection Regulation (GDPR) states the end-user has the right to not involve in a decision, which only made by an AI-system without human intervention. Furthermore, the article 13 to 15 require the controller to provide meaningful information about the logic involved when the data is collected from the user \citep{EU2018GDPR}. \\

With the raise of concerns and regulations, a new strategy has to be developed to conquer the disadvantages of deep neural network and fulfill the requirements of provisions. Moreover, if the AI system want to be adopted and deployed broadly, relieving  the concern of untrustworthiness will be necessary. People is more prone to believe the prediction of black-box models if guaranteed that the output is traceable and understandable. A NIPS conference hold at 2018 conducted a thought experiments, which asks audience to decide which surgeon they would prefer to operate a life-saving surgery for them. The first option was a human surgeon who could explain the details of the surgery for you when had 85\% success rate. On the other side, the second option was a robot who could achieve 98\% success rate but no explanations would be provided and no question would be answer by the robot. At the end, the robot only received 1 vote among hundreds of audience from different domains \citep{Rudin2019LessonFromAICompetition}. The above example highlights the importance of explanation in reliability. Considering the issues mentioned above, we need the approach of explainable artificial intelligence (XAI) to convince the end-user to trust the AI system. \\

% p.5 Current XAI approach and some cases on medical or not medical image data. (One common strategy in research of computer vision is the saliency map.)
Explainable artificial intelligence (XAI) is a set of approaches to extract the insight of decision making process from black-box model. The retrieved insight provides meaningful information for users to comprehend how a specific output from AI system is obtained. Currently, multiple approaches has been developed to explain the computational decision made by black-box models. And, the approaches of XAI have been divided to two categories. The first one is to use \textit{transparent} models, which can be contemplated by human at once. However, using transparent model often associated with low performance on complex datasets. Another XAI approach, called post-hoc explaination, is to interpret opaque models after-the-fact. And the advatage of adopting post-hoc method is the interpretation for opaque models, which allow us to obtain both explainability and performance. Therefore, most of the researches target post-hoc explanation. Some common post-hoc approach are being used broadly, such as as LIME \citep{Ribeiro2016LIME}, SHAP \citep{Lundberg2017SHAP} and LINDA \citep{Moreira2021LINDA}. \citet{Ahsan2020LIMEOnCXR} and \citet{Teixeira2021LIMEAndGradCAMOnCXR} use LIME to interpret the results gained from the neural network. In addition, since the research on visualising trained CNN features \citep{Zeiler2014UnderstandCNN} \citep{Simonyan14DeepInside}, a set of activation-based and gradient-based localisation approaches has been developed and frequently used with image data for visualisation purpose, including CAM \citep{Zhou2015CAM}, \citep{Selvaraju2017GradCAM}, GradCAM++ \citep{Chattopadhay2018GradCAM++} and Integrated Gradient \citep{Sundararajan2017IntegratedGradient}. These gradient-based explaination methods are popular on processing image data because the heatmaps generated by these algorithms can overlap on original images to visualise the sailent pixels clearly. \\


% p.6 The gap of current XAI method. (different user group.)
In the work of CheXNet \citep{Rajpurkar2017CheXNet} and CheXNeXt \citep{Rajpurkar2018CheXNeXt}, Class Activation Mappings (CAMs) \citep{Zhou2015CAM} is used for generating heatmaps to show important features during classification. Then they observe that CAMs can successfully localise the pathologies it identified. However, this approach of interpretation can be inconsistent. \citet{Saporta2021BechmarkingSaliencyMethods} conducted a human benchmark to evaluate current saliency methods, which includes GradCAM, GradCAM ++ and Integrated Gradient. The evaluation result shows the saliency methods perform significantly worse than professional radiologists. Therefore, before applying medical AI system on the real cases, multiple issues has to be solved or mitigated to ensure the reliability. \\

% p.6 How would I like to close the gap.
To close the gap of current XAI methods on chest X-ray image, we want to apply multi-modal learning \citep{Ngiam2011MultiModalLearning}. Instead only providing image and diagnosis to the model, other modalities, such as eye tracking data, report text, bounding boxes and clinical data can also be included, as shown in Table \ref{tab:modalities_table}. In this work, we will mainly use the data from 6 different datasets. MIMIC-IV \citep{Johnson2021MIMIC_IV} and MIMIC-ED \citep{Johnson2021MIMIC_IV_ED} provide the clinical data about the patients. MIMIC-CXR \citep{Johnson2019MIMIC_CXR} and MIMIC-CXR-JPG \citep{DJohnson2019MIMIC_CXR_JPG} contain the CXR images and the report text from the hospital where patients took CXR . Eye gaze data \citep{Karargyris2020EyeGazeDataset} includes eye tracking data, segmentation maps, bounding boxes, dictation audio and its transcription. Moreover, REFLACX dataset \citep{Lanfredi2021REFLACX} offers another set of eye tracking information, anomaly locations ellipses, dictation audio and transcription. There are three main reasons why different modalities should be involved. Firstly, we argue that the model can be more gain better performance through receiving more information. Richer information can facilitate the classification process and boosts the robustness of model. Secondly, we believe human recognition pattern can be extracted from the fixation information. And, the fixation information itself or the extracted pattern can be used for improving both performance and explainability. At the last, some of the modalities can be served as both input and output. For instance, \citet{Karargyris2021EyeGazePaper} implement two experiments is their work. One of them feeds fixation information as input to boost the AUC. At another work, eye gaze data is used as a label in output section, which require the model to predict where the radiologists will look at and focus on. Generally, the sight of the radiologists can help us to localise the pathologies, which enhances the explainability of model. The overall framework has been shown in Figure \ref{fig: proposed_framework}. The modalities with dashed border can serve as input or output. Additionally, the four output modalities with blue background are those can provide explainability. These are: eye tracking information, report text, audio \& transcription and anomaly location ellipse.\\

% p.7 Aims of the PhD
This PhD targets on developing a multi-modal learning framework for medical images. The modalities that can be included in pre-training or training phase are chest X-ray image, report text, eye tracking information, utterance of report, segmentation and bounding boxes. Within the framework, an explaination method will be delivered to interpret the computational result of the model, which can helps human to comprehend how the model make decisions. Therefore, the overall function of the framework is to provide a system of explainable Automated chest radiograph interpretation. \\
\\
\\


\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{./images/MultiModalLearningFramework.png}
    \caption{Overview of proposed framework.}
    \label{fig: proposed_framework}
\end{figure}

% \begin{table}[]
% \centering
\begin{longtable}{|m{10em}|m{30em}|}
    \hline
    Modality                                    & Example                                                                                            \\ \hline
    Chest X-ray                                 & \begin{center}\includegraphics[width=.3\textwidth]{images/CXR-image.jpg}\end{center}               \\ \hline
    Report text                                 & \begin{center}\includegraphics[width=.6\textwidth]{images/ReportText.png}\end{center}              \\ \hline
    Eye tracking data                           & \begin{center}\includegraphics[width=.6\textwidth]{images/Fixation.png}\end{center}
    \\ \hline
    Segmentation of 4 key anatomical structures & \begin{center}\includegraphics[width=.3\textwidth]{images/SegmentationMap.png}\end{center}
    \\ \hline
    Bounding boxes of 17 anatomical structures  & \begin{center}\includegraphics[width=.3\textwidth]{images/EyeGazeBoundingBox.png}\end{center}
    \\ \hline
    Anomaly location ellipses                   & \begin{center}\includegraphics[width=.3\textwidth]{images/AnomalyLocationEllipses.png}\end{center}
    \\ \hline
    Clinical Data                               &
    patients' age, gender, temperature, heat rate, respiratory rate, oxygen saturation, systolic/ diastolic blood pressure, pain level, etc.         \\ \hline
    Dictation audio                             & The audio recorded when the radiologists is interpreting chest X-ray images.
    \\ \hline
    Transcription                               & Recorded audio is automatically transcribed into a json file including word timestamp.             \\ \hline
    \caption{\textbf{Modalities can be included in this work.}} % put citation here.
    \label{tab:modalities_table}
\end{longtable}




% \end{table}
% ! Need to put some graphs.
% 0. Road path graph.

% 1. Background and introducing AI in generic.
% 2. Talking about the AI in medical fields.
% 3. Why the medical AI need explanation? because of the decisions in medical cases are important.
% 4. Talking about recent papers.
% 5. 

% There are 2 gaps  we want to close.
% (1) We want to close the gap of explanation on medical decision makings.
% (2) We want to close the gap of using medical data in AI prediction.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{}

\subsection{Literature Review}

%% List the sections that I need to do literature review on.


\lipsum[1]

\subsection{Research Problem and Research Questions}

\lipsum[1]

% Specify your research scope

% Present your research gaps

% State the research questions that follow from each research gap