## Key words

- [x] Medical data
- [x] Clinical data
- [x] EHR (Electronic Health Record)
- [x] Tabular
- [x] Age, Gender

## No clinical data

### 1. [Predicting COVID-19 Pneumonia Severity on Chest X-ray With Deep Learning](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7451075/)

This paper feed the CXR image as input and get multiple binary and numerical output. It doens't use clinical data in the application.

### 2. \*[Clinically Accurate Chest X-Ray Report Generation](http://proceedings.mlr.press/v106/liu19a.htmlx)

Cool one using the CXR image to generate the topics of the report. Then, conditionally generate the sentences corresponding to these topics. And the end, a reinforcement learning system is used for fine-tuning readibility and clinical accuracy. This paper uses both MIMIC and OPEN-I.

### 3. \*[Creation and validation of a chest X-ray dataset with eye-tracking and report dictation for AI development](https://www.nature.com/articles/s41597-021-00863-5)

This is the paper for CXR dataset, it provide two examples in the end of the paper. The first one using eye tracking data to boost the performance of model (prediction model). The second experiments using CXR image only to generate the fixation heatmap and the decision.

### 4. [PadChest: A large chest x-ray image dataset with multi-label annotated reports](https://www.sciencedirect.com/science/article/pii/S1361841520301614)

Just a dataset paper with some annotation strategy.

### 5. \*[Multi-modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training](https://arxiv.org/abs/2105.11333)

The one from Kore. It talks about pre-training and multimodal learning. However, it sitll feed the report text as input. And, it perform multitask learninig, which can generate multiple outputs for different tasks, including Diagnosis Classification, Image-Report Retrieval, Medical Visual Question Answering and Radiology Report Generation.

### 6. [BIMCV COVID-19+: a large annotated dataset of RX and CT images from COVID-19 patients](https://arxiv.org/abs/2006.01174)

Another dataset and annotating strategy.

### 7. [COVIDGR Dataset and COVID-SDNet Methodology for Predicting COVID-19 Based on Chest X-Ray Images](https://ieeexplore.ieee.org/abstract/document/9254002)

This paper propose a model for taking CXR image then,

1. Using Segmentation for cropping the chest part.
2. transform them into a fusion of CNN twins. Since the transformation, the model can have a better performance.
3. Make prediction based on the fusion of CNN twins.

### 8. [On the limits of cross-domain generalization in automated X-ray prediction](http://proceedings.mlr.press/v121/cohen20a.html)

This paper study the generalization issue of X-ray prediction task. It state the issue of generalization is not due to a shift in the images but instead a shift in the labels. It finds interesting discrepancies between performance and agreement where models which both achieve good performance disagree in their predictions as well as models which agree yet achieve poor performance.

### 9. [MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models](https://proceedings.mlr.press/v143/sowrirajan21a.html)

This paper provide a method of pre-training, MoCo-CXR. This algorithm is an adaption of the contrastive learning method Momentum Contrastive, to produce models with **better representations and initializations** for the detection of pathologies in chest X-rays.

(Note: Contrastive learning maximizes agreement of embeddings generated by different augmentations of the same chest X-ray image.)

### 10. [Automated abnormality classification of chest radiographs using deep convolutional neural networks](https://www.nature.com/articles/s41746-020-0273-z)

This paper provides multiple CNN for abnormality classification.

### 11. [CheXclusion: Fairness gaps in deep chest X-ray classifiers](https://www.worldscientific.com/doi/abs/10.1142/9789811232701_0022)

### 12. [Interpreting chest X-rays via CNNs that exploit hierarchical disease dependencies and uncertainty labels](https://www.sciencedirect.com/science/article/pii/S0925231221000953?casa_token=-mrhEvQxsaYAAAAA:1vz9y4Hc0q7QWghLucTefHn1Rl8nWk21TJoN6-qjiRORC2KfKd4TKWWcDz5mhwty-LsykSDmFA)

Ensemble CNN in this paper.

### 13. [CheXbert: Combining Automatic Labelers and Expert Annotations forAccurate Radiology Report Labeling Using BERT](https://arxiv.org/pdf/2004.09167.pdf)

It proposes a labeling strategy to generate labels from the radiologiests' report text by a BERT-based model.

### 14. [Can we trust deep learning based diagnosis? The impact of domain shift in chest radiograph classification](https://arxiv.org/pdf/1909.01940.pdf)

It evaluates the extent of **domain shift** on four of the largest datasets of chest radiographs.

### 15. [Deep learning in generating radiology reports: A survey](https://www.sciencedirect.com/science/article/pii/S0933365719302635?casa_token=pZSJa9oS1FEAAAAA:PkrVT16EbXYciIsob830jx7zgWYG8jAxKC6UaWdbmMASkffio1ApKnUc0J2IquYL27ThMSD54w)

as the title.

![image](https://user-images.githubusercontent.com/37566901/141138392-f96be232-f992-496c-88a5-32e4207030d1.png)

### 16. [Baselines for Chest X-Ray Report Generation](http://proceedings.mlr.press/v116/boag20a)

![image](https://user-images.githubusercontent.com/37566901/141229989-d1ce3a98-5848-4e5c-b6ef-d77e457cd95e.png)
![image](https://user-images.githubusercontent.com/37566901/141230061-eaf11faa-28cf-42cf-867b-2c82256bd4fe.png)

This study profiles a number of text-generation models for automatic radiology report generation across evaluation metrics spanning linguistic quality (BLEU-1 through BLEU-4, CIDEr) as well as clinical efficacy (CheXpert accuracy, precision, and F1).

### 17. [CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning](https://arxiv.org/pdf/1711.05225.pdf)

![image](https://user-images.githubusercontent.com/37566901/141231944-838b7557-18a2-47bd-ad77-2d6738292a04.png)

Using CXR-image only to outperform the human radiologist in the task of pneumonia detection.

### 18. [Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists](https://stanfordmlgroup.github.io/projects/chexnext/)

This paper is s for detecting 14 clinically important diseases with heatmap provided.

### 20. [Combining chest X-rays and EHR data using machine learning to diagnose acute respiratory failure](https://arxiv.org/abs/2108.12530)

It uses clinical data from electronic health record (EHR<text report>)

### 21. [Variational Knowledge Distillation for Disease Classification in Chest X-Rays](https://arxiv.org/abs/2103.10825)

![image](https://user-images.githubusercontent.com/37566901/141231470-171b0470-3103-42f9-944b-645f841efaf8.png)

![image](https://user-images.githubusercontent.com/37566901/141231446-1106d6ea-4770-4b2b-9d04-2bb29a73ca3d.png)

This paper use EHR (structure) and CXR-image to make prediction.

### 22. [A ROBUST NETWORK ARCHITECTURE TO DETECT NORMAL CHEST X-RAY RADIOGRAPHS](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9098671)

This paper just propose a CNN model architecture (involve inverse-CNN).

![image](https://user-images.githubusercontent.com/37566901/141266713-988ca8d0-b159-49be-8ad9-65e17dd6327b.png)

### 23. [Health Informatics: Clinical Information Systems and Artificial Intelligence to Support Medicine in the CoViD-19 Pandemic](https://ieeexplore.ieee.org/abstract/document/9565764?casa_token=sn3qJrBJQAcAAAAA:zRphFa6P-Z28GCJ8SHuLnPW1erlggs7-doNpnOvpZVM3H8TidYC-6W0VkwVN-TfGQh5R0hVi4u0)

Just another literature review in skin-deep level.

### 24. [COVID-19 PROGNOSIS VIA SELF-SUPERVISED REPRESENTATION LEARNING AND MULTI-IMAGE PREDICTION](https://arxiv.org/pdf/2101.04909.pdf)

- This one use MIMIC for pre-training and use COVID-19 Dataset and Deterioration Labels to fine tune the model.
- It uses contrast training
  ![image](https://user-images.githubusercontent.com/37566901/141284729-d33c0f8a-a0cb-437e-8b78-92e61e4e7d1e.png)

- It use sequence of the CXR-image according to the scam time.
  ![image](https://user-images.githubusercontent.com/37566901/141284890-3a554ba1-9b71-4a6d-9f11-22e268164f72.png)

### 25. [EMIXER: End-to-end Multimodal X-ray Generation via Self-supervision](https://arxiv.org/pdf/2007.05597.pdf)

This paper use GANs to generate CXR images and reports. It states that these generated CXR-images and reprot text can benefit the performance of classifier.

![image](https://user-images.githubusercontent.com/37566901/141286523-513aace1-9b3b-4029-8e66-70647354d0ba.png)

### 26. [Reinforcement Learning with Imbalanced Dataset for Data-to-Text Medical Report Generation](https://aclanthology.org/2020.findings-emnlp.202/)

![image](https://user-images.githubusercontent.com/37566901/141299851-b497c3dd-bf80-4a33-ad9f-b606b85ddaeb.png)

![image](https://user-images.githubusercontent.com/37566901/141301981-9aa5f71c-226b-4ec6-b53b-2d736682b9a6.png)

![image](https://user-images.githubusercontent.com/37566901/141303334-715ae8f7-1dfb-46a3-95b2-e1136d2af1b4.png)

This one is pretty strange... it involve the readiology to modify or correct the diagnosis from the model. Then, put the modified diagnosis to the report generator.
If the label is modified from a radiologist, then radiologist can write a report and make diagnosis by himself. Why do we need a model to generate some diagnosis for the radiologist to re-diagnose the same patient and correct the prediction of the model? Moreover, the text generator only take the labels as the input without any information from the image. It means no matter what the image looks like, if they have same label, the report text will be the same. If a patient has slightly _Cardiomegaly.Positive_ and another has severe _Cardiomegaly.Positive_, because their lables are the same, the report can't show the difference between these two patient.

### 27. [Show, tell and summarise: learning to generate and summarise radiology findings from medical images](https://link.springer.com/article/10.1007/s00521-021-05943-6)

This model use 2 steps approach to generate the report. The first step is to generate the findings from X-ray. Secondly, sumarizing them to provide impression section. In the second stage, it also uses different model for generating normal and abnormal reports.

![image](https://user-images.githubusercontent.com/37566901/141308085-1edd8777-5771-448b-8a9e-14b4c4de5f2e.png)

![image](https://user-images.githubusercontent.com/37566901/141308169-a3c46e03-ca42-4f38-ab11-9a3e7d17160c.png)

(It can make a gateway for summarisation model to retrieve the information from the image.)

![image](https://user-images.githubusercontent.com/37566901/141308416-6c5d9f24-85ee-46bb-9b5a-aca022aa2b95.png)

### 28. [Deep learning applied to automatic disease detection using chest X-rays](https://onlinelibrary.wiley.com/doi/full/10.1111/1754-9485.13273?casa_token=QgvAjLsXFacAAAAA%3AKNiiR7Go9uTjDLDAcEZnLzi3uwGrej6lVV202mXeRvgiDfsFkOjZzP9I1UBXjyFV-fINgTXYNDyuD08)

- It uses transfer learning
  ![image](https://user-images.githubusercontent.com/37566901/141324258-64ff193f-da8e-4fc0-af55-5ae925e195f7.png)
  other than that, it's pretty basic one.

### 29. [Individual predictions matter: Assessing the effect of data ordering in training fine-tuned CNNs for medical imaging](https://arxiv.org/abs/1912.03606)

[CheXNet Reproduce](https://github.com/jrzech/reproduce-chexnet)

Is this one pre-split the data before changing the random seed? cuz if it change it before the splitting, it will cause the training and test dataset to be built differently. Wihtout the code being available, I don't believe what this paper does.

[Code here](https://github.com/jrzech?tab=repositories)

### 30. [Deep Learning Methods for Screening Pulmonary Tuberculosis Using Chest X-rays](https://www.tandfonline.com/doi/full/10.1080/21681163.2020.1808532?casa_token=QXanWJ7DfNIAAAAA%3ADRlUF9eleLzd5yHb-mGoboytKu-lp_qCT9eIzwC9X1LMY-d2w2v07jHw7NSL4HzzrI17_wKYSBq_iA)

- The presented deep learning pipeline consists of three different modern deep learning architectures, to generate, segment, and classify lung X-rays.
- I'm not really sure why does the propsed pipeline helpful for classification task (pre-training?)?

### 31. \*[Big Self-Supervised Models Advance Medical Image Classification (Google)](https://arxiv.org/abs/2101.05224)

![image](https://user-images.githubusercontent.com/37566901/141345990-d841e869-fd64-4e14-a27f-0cb61b2882cb.png)
prove that self-supervise learning is important.

### 32. \*[Neural Natural Language Processing for UnstructuredData in Electronic Health Records: a Review](https://arxiv.org/pdf/2107.02975.pdf)

This paper list all of the tasks we can do for the text data in EHR.

### 33. \*[Multimodal Machine Learning for Automated ICD Coding](http://proceedings.mlr.press/v106/xu19a/xu19a.pdf)

![image](https://user-images.githubusercontent.com/37566901/141348196-d441d448-3f99-43a5-9b82-19b92afbfddc.png)

Using both text data and tabular data in EHR to make classification.

### 34. \*[Improving Pneumonia Localization via Cross-Attention on Medical Images and Reports](https://link.springer.com/chapter/10.1007/978-3-030-87196-3_53)

This one use the CXR-image to generate the bouding box. During training, it uses the report text (from radiologists) to assist training.

![image](https://user-images.githubusercontent.com/37566901/141349492-e27902e4-5d55-445c-9443-8db9da5bdc46.png)

### 35. \*[Enhanced Diagnosis of Pneumothorax with an Improved Real-Time Augmentation for Imbalanced Chest X-rays Data Based on DCNN](https://ieeexplore.ieee.org/abstract/document/8693998?casa_token=opNMNrSF8gQAAAAA:ILPbUZHtim0DozB250PHZ2YFd4YbBOrQjSB8V0LJu-wwCV6vYTgrY1dM5OjAbablXXr0rceXNM4)

- This is a paper using image as the input to make diagnosis.
- Approach:

  ![image](https://user-images.githubusercontent.com/37566901/141406757-49108bb6-57a8-43d5-9b7a-7ffbb3c87e71.png)

  - **A**. Medical format conversion.

    Tranform the image from DICOM format to PNG.

  - **B**. The two NIN network cascades are used to clean the original dataset.

    The first network is a classifier to eliminate the image not front CXR-image. And, the second network is to detect the CXR in different orientation.

  - **C**. A new method of data augmentation based on random histogram equalization is added.
    Augmenting the CXR-image

    ![image](https://user-images.githubusercontent.com/37566901/141405209-74f073b4-ae0a-4a28-8c87-a5a4a3b1c2e4.png)

  - **D**. A 19-layer network for highresolution images, called ChestNet

    ![image](https://user-images.githubusercontent.com/37566901/141406581-da12e645-e2e8-4212-bf34-81807e904ad4.png)

  - **E**. The lesion area features of the classification network are visualized.

    ![image](https://user-images.githubusercontent.com/37566901/141407136-61df32d7-8fef-4385-ad0b-a7b20cb4310c.png)

### 36. [The importance of standardisation – COVID-19 CT & Radiograph Image Data Stock for deep learning purpose](https://www.sciencedirect.com/science/article/pii/S0010482520304236?casa_token=FyB5WKo9y88AAAAA:bSmDNPTXjE0FQWH06zUrgQZ0oXXAqid1j94cjHsHMR_qN4wNOzONGaGtNmdAuq6YFzFlutLDDg)

- It's a dataset paper.
- It contains both CT (Computed Tomography) and radiograph samples of COVID-19 lung findings and combines them with additional data to ensure a sufficient number of diverse COVID-19-negative sample.
- No tabular data we want provided.
  
  ![image](https://user-images.githubusercontent.com/37566901/141408345-f3d5ab09-b64c-4197-8a86-9a4a72867f31.png)

### 37. [Localization of Critical Findings in Chest X-Ray Without Local Annotations Using Multi-Instance Learning](https://ieeexplore.ieee.org/abstract/document/9098551?casa_token=GieYHeav0FwAAAAA:RyXIk-4AdJmMYwssOzUhSv_JCC9U1EU7ZpXIwQUJoE48-QzWduaZb1EMux1uHY5HFhtFDxhUTCg)

- Don't really understand this paper.,
- It doesn't clearly state how the patchs generated.

![image](https://user-images.githubusercontent.com/37566901/141429467-32098f94-5b8e-4953-893c-da0c0ced8f10.png)

### 38. \*[A Survey of Modern Deep Learning based Object Detection Models](https://arxiv.org/pdf/2104.11892.pdf)

We can use the object detection model from here to do abnormality detection.

### 39. \*[Incorporating Uncertainty in Learning to Defer Algorithms for Safe Computer-Aided Diagnosis](https://arxiv.org/abs/2108.07392)

![image](https://user-images.githubusercontent.com/37566901/141438652-89ee1858-869c-43f2-9d24-ec5c5eb8f267.png)

- Stage 1 is for prediction, Stage 2 is checking the defer.
- How can we train the model to know when to defer? (Where does the dataset come from?)
- It use image, text and tabular data for different tasks. Therefore, it's not a case with multi-modal learning.

### 40. [On the Composition and Limitations of Publicly Available COVID-19 X-Ray Imaging Datasets](https://arxiv.org/pdf/2008.11572.pdf)

- It's a peper analysing datasets which containing or not containing Covid-19 X-Ray.

![image](https://user-images.githubusercontent.com/37566901/141441150-bf085283-19d3-4b6b-b1a4-72d3fd517c58.png)

### 41. [An empirical framework for domain generalization in clinical settings](https://dl.acm.org/doi/abs/10.1145/3450439.3451878)

- Benchmarking the performance of eight domain generalization methods on multi-site clinical time series and medical imaging data.
- Method:
  
  ![image](https://user-images.githubusercontent.com/37566901/141465323-9144de69-a5a7-4f9e-9d0e-e3c60bd06fe9.png)
  ![image](https://user-images.githubusercontent.com/37566901/141465507-541e250f-3998-46ec-8608-7fd25c9e0499.png)

### 42. [LOCAL ADAPTATION IMPROVES ACCURACY OF DEEP LEARNING MODEL FOR AUTOMATED X-RAY THORACIC DISEASE DETECTION : A THAI STUDY](https://arxiv.org/pdf/2004.10975.pdf)

- Predition paper using CNN.
- Our work emphasizes the importance of investing in local research of medical diagnosis algorithms to ensure safe and efficient usage within the intended region.

### 43. [An Adversarial Approach for the Robust Classification of Pneumonia from Chest Radiographs](https://dl.acm.org/doi/pdf/10.1145/3368555.3384458)

- Adversarial predictions improve model interpretability by identifying potentially confounded models.
- Adversarial training can increase model robustness by controlling for confounders
- The problem of the medical classifier is the data shift issue.
- when the model was tested on radiographs from a third hospital not present in the training data its performance signi!cantly decreased.

### 44. [Automated Pleural Effusion Detection on Chest X-Rays](https://scholar.smu.edu/cgi/viewcontent.cgi?article=1093&context=datasciencereview)

- Identify Pleural Effusion using CXR-image to feed in CNN.
- We demonstrate that our model is able to reproduce current baseline performance for this task with a model that is 10x smaller and 30x faster.

### 45. [Machine-learning-based multiple abnormality prediction with large-scale chest computed tomography volumes](https://www.sciencedirect.com/science/article/pii/S1361841520302218?casa_token=gAi-eFFtqWcAAAAA:A1eVI7vbuF9277AnK6cPPxw4cqRO1vxqx2JS6wtNsdggpO6GMePsbSquQNfy9ND7zJMsaymWjw)

- Extracting labels from CT reports.
- Using CT volume to predict the report.
- Architecture is ResNet
  
![image](https://user-images.githubusercontent.com/37566901/141604710-bc552bd9-5a5b-4111-93b1-9447df2b6ee4.png)

### 46. [A deep learning method for classification of chest X-ray images](https://iopscience.iop.org/article/10.1088/1742-6596/1848/1/012030/pdf)

- Using **foacl lsos function** to address the problem of inbalanced data.
- The input is the X-ray image, and the output is the probabilities of 14 chest pathologies.
- THe architecture is **AM_DenseNet** (proposed).
  
![image](https://user-images.githubusercontent.com/37566901/141612019-2054c421-9491-43d4-a444-0255b26f6748.png)


(Note: I feel the disease output should be 14 of binary outputs.)

### 47. [CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison]()

- It's a dataset from Stanford containing 224,316 chest radiographs of 65,240 patients.
- Using a labeler to automatically detect 14 observations in radiology reports, capturing uncertainties inherent in radiograph interpretation.
- We investigate different approaches to using the uncertainty labels for training convolutional neural networks that output the probability of these observations given the available frontal and lateral radiographs.
  
![image](https://user-images.githubusercontent.com/37566901/141613053-1c98aa27-f117-4948-8938-45726956ba73.png)


### 48. [Interpreting chest X-rays via CNNs that exploit hierarchical disease dependencies and uncertainty labels](https://www.sciencedirect.com/science/article/pii/S0925231221000953?casa_token=Bz7JJ9FGya0AAAAA:LlRe4MYguYdzajncaAg5DzH3534j95DHEXJ_pkxeIwcZnV1DU7QXh18Orm1zC2sj60OzDCSM-w)

- Using CXRs as input and CNN as the architecture to predict several specific pathologies.
  
![image](https://user-images.githubusercontent.com/37566901/141613264-772ab78c-4a52-4917-8318-291fba189cf9.png)
- Using **DenseNet-121**
- Conditional training to learn dependencies among labels


### 49. [Graph-Based Deep Learning for Medical Diagnosis and Analysis: Past, Present and Future](https://arxiv.org/abs/2105.13137)

- In this survey, we thoroughly review the different types of graph architectures and their applications in healthcare. 
- We provide an overview of these methods in a systematic manner, organized by their domain of application including functional connectivity, anatomical structure and electrical-based analysis.


### 50. [An Extensive Survey of Machine Learning Based Approaches on Automated Pathology Detection in Chest X-Rays](https://ieeexplore.ieee.org/abstract/document/9347605?casa_token=YiJZ6KXJ1AkAAAAA:uHaE02O-fyFQQ0x7f0C2dDUgCPyxrGAtMJUrsmF3aYRjtIgYtWavL-H1tyn7v8PNM2do3GYHYPw)

- This paper conducts an extensive survey on existing machine learning apporaches, it's dataset and techniques on pathology detection in chest X-Rays. 
- Popular datasets, image processing techniques and current machine learning architecture.
  
![image](https://user-images.githubusercontent.com/37566901/141647723-1b7099dd-4acc-4958-958a-8c3da3af4d66.png)
![image](https://user-images.githubusercontent.com/37566901/141647743-9aba1615-f357-4170-b27e-b7152ab1d05d.png)
![image](https://user-images.githubusercontent.com/37566901/141647767-477e6202-ac27-477d-b787-964bd2a9cd40.png)

### 51. [Medical imaging algorithms exacerbate biases in underdiagnosis](https://assets.researchsquare.com/files/rs-151985/v1_covered.pdf?c=1631852850)

- In this work we examine algorithmic underdiagnosis in chest X-ray pathology classifiers and find that classifiers consistently and selectively underdiagnose under-served patients, actively amplifying the existing biases in clinical care.
- Our work demonstrates that deploying AI systems risks exacerbating biases present in current care practices. 

![image](https://user-images.githubusercontent.com/37566901/141652912-86b531f2-bc74-4c4d-8a54-c4c143c3dee8.png)


### 52 [Computer Assisted Reading of Chest Radiographs](https://ieeexplore.ieee.org/abstract/document/8969538?casa_token=w2oUM7160dUAAAAA:-0X1wYoQL97tlVjCS-u-b3AZXasf3HA151p4fAraPPZP8L7N_JNQsc7-H7LMM1AoyaGsKoDRLPo)

- In this work we report an implementation of a deep-learning based framework to interpret the disease signature from chest X-rays. The model was trained on a large dataset consisting of both frontal and lateral X-ray images of the chest with multiple thoracic disease labels. 
- Architecture:
  
![image](https://user-images.githubusercontent.com/37566901/141653467-aaebbd34-02dd-4774-88f9-9301862f3259.png)
- Input is CXR image (including frontal and lateral), and the output is 8 sigmoid nodes with each disease.
- using **“Learning deep features for discriminative localization** paper to generate a colormap for localise the disease.

 

<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>

## With clinical data

### 1. [Multitask and Multimodal Neural Network Model for Interpretable Analysis of X-ray Images](https://ieeexplore.ieee.org/abstract/document/8983272?casa_token=NhxHEG444tQAAAAA:_SgP02KWPYFybvMZ6UiaFNr9dMOeYcEg-vsaQRiA8F5aI8R1YGTs4piu585ISHZ7MBVi_CvepS0)

![image](https://user-images.githubusercontent.com/37566901/141148916-3584231c-4029-4eb8-9b75-3e7d22db58d5.png)

### 2. [Deep learning predicts hip fracture using confounding patient and healthcare variables](https://www.nature.com/articles/s41746-019-0105-1.pdf)

- This one using image and these variables to predict hip fractures.

![image](https://user-images.githubusercontent.com/37566901/141504494-22c5b49f-066d-4179-9067-c8eed3f4fe1b.png)

- has code [here](https://github.com/mbadge/hipsMultimodal)
