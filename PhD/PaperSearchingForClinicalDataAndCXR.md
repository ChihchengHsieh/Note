## No clinical data

### 1. [Predicting COVID-19 Pneumonia Severity on Chest X-ray With Deep Learning](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7451075/)

This paper feed the CXR image as input and get multiple binary and numerical output. It doens't use clinical data in the application.

### 2. *[Clinically Accurate Chest X-Ray Report Generation](http://proceedings.mlr.press/v106/liu19a.htmlx)
Cool one using the CXR image to generate the topics of the report. Then, conditionally generate the sentences corresponding to these topics. And the end, a reinforcement learning system is used for fine-tuning readibility and clinical accuracy. This paper uses both MIMIC and OPEN-I.

### 3. *[Creation and validation of a chest X-ray dataset with eye-tracking and report dictation for AI development](https://www.nature.com/articles/s41597-021-00863-5)

This is the paper for CXR dataset, it provide two examples in the end of the paper. The first one using eye tracking data to boost the performance of model (prediction model). The second experiments using CXR image only to generate the fixation heatmap and the decision.

### 4. [PadChest: A large chest x-ray image dataset with multi-label annotated reports](https://www.sciencedirect.com/science/article/pii/S1361841520301614)
Just a dataset paper with some annotation strategy.

### 5. *[Multi-modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training](https://arxiv.org/abs/2105.11333)

The one from Kore. It talks about pre-training and multimodal learning. However, it sitll feed the report text as input. And, it perform multitask learninig, which can generate multiple outputs for different tasks, including Diagnosis Classification, Image-Report Retrieval, Medical Visual Question Answering and Radiology Report Generation.

### 6. [BIMCV COVID-19+: a large annotated dataset of RX and CT images from COVID-19 patients](https://arxiv.org/abs/2006.01174)
Another dataset and annotating strategy.

### 7. [COVIDGR Dataset and COVID-SDNet Methodology for Predicting COVID-19 Based on Chest X-Ray Images](https://ieeexplore.ieee.org/abstract/document/9254002)

This paper propose a model for taking CXR image then,
1. Using Segmentation for cropping the chest part.
2. transform them into a fusion of CNN twins. Since the transformation, the model can have a better performance.
3. Make prediction based on the fusion of CNN twins.

### 8. [On the limits of cross-domain generalization in automated X-ray prediction](http://proceedings.mlr.press/v121/cohen20a.html)

This paper study the generalization issue of X-ray prediction task. It state the issue of generalization is not due to a shift in the images but instead a shift in the labels. It finds interesting discrepancies between performance and agreement where models which both achieve good performance disagree in their predictions as well as models which agree yet achieve poor performance.


### 9. [MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models](https://proceedings.mlr.press/v143/sowrirajan21a.html)

This paper provide a method of pre-training, MoCo-CXR. This algorithm is an adaption of the contrastive learning method Momentum Contrastive, to produce models with **better representations and initializations** for the detection of pathologies in chest X-rays.

(Note: Contrastive learning maximizes agreement of embeddings generated by different augmentations of the same chest X-ray image.)


###


## Have clinical data
